\section{Neural Networks}

% ##############################################################################
\subsection{Artificial Neural Networks}
\label{ssec:ArtificialNeuralNetworks}

Neural networks are computing systems that are inspired by, but not identical to, biological neural networks that constitute animal brains. Such systems essentially \emph{learn} to perform tasks by considering multiple samples, generally without being programmed with task-specific rules. They form a basis for deep machine learning~\cite{goodfellow2016dl}.

The goal of a neural network is to approximate some unknown function $f$. For instance, when considering a classiÔ¨Åer, the transformation $y = \func{f}{\vx}$  maps the given input $\vx$ to a category $y$. Such a network, therefore, defines a mapping and learns the value of the parameters that result in the best function approximation.

These models can be described with a directed acyclic graph denoting the sequential composition of several functions. More concretely, we might have three functions $\suprbrackets{f}{1}$, $\suprbrackets{f}{2}$ and $\suprbrackets{f}{3}$, forming a chain, $\func{f}{\vx} = \func{\suprbrackets{f}{3}}{\func{\suprbrackets{f}{2}}{\func{\suprbrackets{f}{1}}{\vx}}}$. These chain structures are the most commonly used structures in neural networks. Deep machine learning consists of multiple such layers of neurons that are trained using the \emph{backpropagation} algorithm~\cite{rumelhart1986backprop}.

% ##############################################################################
\subsection{Convolutional Neural Networks}
\label{ssec:ConvolutionalNeuralNetworks}

This type of neural network has gained popularity in the computer vision community thanks to a never-seen-before performance on image classification task~\cite{krizhevsky2012classification}. This approach processes images or other high dimensional, grid-like input and then learns the importance (weights and biases) of various aspects of the input data.

The successful ability of these networks to capture spatial properties via learned convolutional filters is the fundamental principle. Let $f$ and $g$ be functions. Then, the operation of convolution denoted by $\star$ produces a third function, as a result of the following computation (demonstrating the commutativity property, too)~\cite{goodfellow2016dl}:
\begin{equation}
    \label{eq:ConvolutionContinuous}
    \func{\rbrackets{f \star g}}{t} =
    \int_{-\infty}^{\infty}
    \func{f}{\tau}
    \func{g}{t - \tau}
    d\tau =
    \int_{-\infty}^{\infty}
    \func{f}{t -\tau}
    \func{g}{\tau}
    d\tau.
\end{equation}
In this setting, $f$ is the input, $g$ is the kernel, and the output of this operation is a feature map. During training, the aim is to learn the weights of the kernel matrix that produces a feature map based on which the model can solve the given task.

Let $I$ be a two-dimensional input image and $K$ be a two-dimensional kernel. Then, for a given position $\rbrackets{i, j}$ in the input image $I$, the discrete convolution can be written as
\begin{equation}
    \label{eq:ConvolutionDiscrete}
    \func{\rbrackets{f \star g}}{i, j} =
    \sum_{m}
    \sum_{n}
    \func{I}{m, n}
    \func{K}{i - m, j - n}.
\end{equation}
Many machine learning libraries implement the cross-correlation operation, not the convolution operation by its strict definition. This operation is the same except for the fact that the kernel is not flipped. Thus, the result of the cross-correlation is given by

\begin{equation}
    \label{eq:CrossCorrelation}
    \func{\rbrackets{f \star g}}{i, j} =
    \sum_{m}
    \sum_{n}
    \func{I}{i + m, j + n}
    \func{K}{m, n}.
\end{equation}

An indispensable outcome of \glspl{cnn} is the ability to capture hierarchical relations. Layers placed near the input of the model capture low-level features such as edges, colors, gradient orientations, and so on. On the other hand, layers placed further, deeper in the model, highlight semantic, abstract features that are specific to the task at hand.

Another prominent use case of \glspl{cnn} is \emph{transfer learning}, where a pre-trained model is adopted for a new task, utilizing the already learned features. These pre-trained models may come in various flavors, but typical ones are pre-trained for an image classification task using the \datasetname{ImageNet} dataset~\cite{deng2009imagenet}. The reasoning is that visual features such as edges and contours are vital to general object recognition tasks, hence it is not needed to learn coarse, rudimentary, low-level features from scratch all the time.
