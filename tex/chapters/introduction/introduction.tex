\chapter{Introduction}
\label{chap:Introduction}

\Gls{vot} is one of the principal challenges in the field of computer vision and has consistently been a popular research area over the last two decades. Briefly speaking, the objective is to locate a certain object in all frames of a video, given only its location in the first frame. From a technical perspective, an object is firstly detected in the image (frame), a unique identifier is assigned to it, and subsequently, and then the same identifier has to be correctly assigned if the object is present in future images from the scene. Tracking can also be considered a task of estimating an objectâ€™s trajectory throughout a sequence of images, such as video frames.

\Gls{vot} is a task at which people perform reasonably well, but when it comes to computers, it is considered practically unsolved. With this in mind, object tracking is the task of following one or more objects in a scene, from their first appearance to their exit~\cite{forsyth2012computer}. In general, this problem is still wide-open, with \gls{sota} performances lagging far behind human levels. However, there are successful real-world applications, particularly when a certain amount of control over the environment is possible, e.g. in industrial settings. Major difficulties stem from a change in object illumination, position, and orientation due to movement, object and camera viewpoint variations, and partial or full occlusion after which the object re-emerges in the scene again~\cite{jalal2012sotavot}.

There is extensive literature covering different approaches. Since $2013$, there has even been a standard benchmark in the field, called the \gls{vot} Challenge~\cite{webvotchallenge}, which maintains datasets that researchers and individuals can use to benchmark their algorithms. Another competitive type of benchmark exists under the name \gls{otb}~\cite{wu2015otb}. Additionally, a similar type of evaluation and comparison of numerous approaches for the \gls{mot} exists since $2014$ under the name \gls{mot} Challenge~\cite{webmotchallenge}, too. Such an extensive endeavor to push the boundaries of object tracking performance supports the relevancy of this topic.

The goal of an object tracker is to produce a trajectory of a given object with respect to time using its position in every video frame. A practically unattainable, an ideal tracking algorithm, should as a result have the properties below~\cite{jalal2012sotavot}:
\begin{itemize}
    \item properly detect all the objects that enter and exit the scene,
    \item differentiate between instances of multiple objects,
    \item consistently maintain the uniquely assigned identifier to each object,
    \item motion of the object or lack thereof should not influence the object tracking,
    \item partial or full object occlusion, even a long-term one, should be resolved.
\end{itemize}

From a methodological perspective, \gls{vot} may be tackled in two fundamentally distinct ways, namely \emph{top-down} and \emph{bottom-up}~\cite{jalal2012sotavot}. The top-down methodology employs \emph{forward tracking}, which means that an attempt is made at every frame to locate the object given some initial hypothesis~\cite{comaniciu2003kernel}. On the other hand, the bottom-up approach utilizes the object detection first and then the adequate correspondence is established with previously detected objects~\cite{wren1997pfinder}. We plan to analyze and exploit the capabilities of the \gls{sota} object detectors to localize objects of interest (primarily vehicles in our use case) and then build the object tracking pipeline.

The field of computer vision has provided diverse approaches to visual tracking in the past decades, e.g. using geometry and manual feature-engineering in combination with Kalman filtering~\cite{kalman1960linearfilter} for predicting future states. The Hungarian algorithm~\cite{kuhn1995hungarian} is the most commonly used to solve the minimum cost assignment problem, as utilized by~\cite{bawley2016simple}.

However, the most influential approaches were the ones involving the modern tools of machine learning, specifically deep machine learning. Deep learning can perform global generalization, which makes it a valuable tool as a function approximator, so the utilization is vast. This revolutionary idea which has in the past decade reaped an upsurge in its utility will be the key element of this thesis and we will devote the largest portion of our work to it. Krizhevsky~\etal{}~\cite{krizhevsky2012classification} showed that an outstanding tool, when it comes to the application of deep learning in computer vision, are \glspl{cnn} (\sectionstr{}~\ref{ssec:ConvolutionalNeuralNetworks}). It is a predominant approach to extract valuable visual features from the pixel space of images.

Visual tracking of single or multiple objects is often just an intermediate step for various ends, such as traffic analysis~\cite{tang2019cityflow}, whether from a static camera or as part of self-driving cars, pedestrian detection and tracking~\cite{lealtaixe2017tracking}, activity understanding~\cite{finn2017oneshotimitation}, and imitation based on a video~\cite{peng2018sfv}. While this is an important problem with annually occurring challenges for the best achievement, the current \gls{sota} solutions still lack high accuracy in unconstrained scenarios with potential object occlusion~\cite{jiyan2007robustocclusion}. Understandably, the object might re-emerge after the occlusion in a significantly different form, thus it might be mistaken for a new object. Occlusion comes in three separate types~\cite{gabriel2003sotamot}:
\begin{itemize}
    \item \emph{self-occlusion}, where the object occludes itself (a person holding a phone),
    \item \emph{intra-object occlusion}, in which multiple different objects occlude each other (a small vehicle passing behind a truck),
    \item or \emph{object-background occlusion}, when the occlusion is caused by a static object in the background (a tree occluding a cat).
\end{itemize}
In traffic scenarios, the last two types are prevalent.

A key element for a tracking algorithm to hold onto when dealing with occlusion is to discern between new and previously seen objects. For this purpose, a repeated identification of some object, or \gls{reid}, is indispensable. Various advances in the creation of latent spaces and so-called \emph{embeddings} using deep neural networks (\sectionstr{}~\ref{ssec:ArtificialNeuralNetworks}) have shown promising results~\cite{schroff2015facenet, taigman2014deepface}. One use case of embeddings is to create a metric space into which the tracked visual objects are encoded as vectors. It is a form of dimensionality reduction, where similar objects are mapped onto a manifold closer together while distinct objects are mapped further away from each other~\cite{hadsell2006dimreduction}. Later on, the Euclidean distance or cosine similarity between any two vectors results in a high degree of similarity if the two visual samples belong to the same object.

A broad range of real-life applications requires tracking multiple objects, which only adds complexity to an already tough problem itself. But~\cite{kuma2019vehiclereid} shows that approaching the problem of vehicle \gls{reid} using embeddings (section \ref{sec:LatentSpacesAndEmbeddings}) trained with contrastive or triplet loss (section \ref{ssec:SiameseAndTripletNetworks}) brings substantial improvement. We plan to explore this idea and utilize it as a basis for \gls{vot} when it comes to repeatedly re-identify occluded objects.

The primary objective of this thesis is to explore, implement, and experiment with methods for \gls{vot} using tools of deep learning, primarily \glspl{cnn}. Given the potential for improvement, considering the performance of \gls{sota} approaches as well as the practical demand for an accurate tracking outcome, be it traffic or other scenarios~\cite{tang2019cityflow}, we think that an emphasis should be put on occlusion (partial or full) handling, as it causes major difficulties for existing methods~\cite{jiyan2007robustocclusion}.

The secondary objective is to extend the current knowledge in the field of computer vision and deep machine learning regarding dynamic scenes involving \gls{vot}. Nowadays, at the time of writing this document, there is still a lack of freely available implementations. Widely used open-source libraries such as OpenCV~\cite{bradski2000opencv} provide only tracking algorithms for single objects, as opposed to \gls{mot}, which is demanded in practice, yet concrete solutions exist but are not ubiquitous and easy to use. Visual tracking in the presence of occlusion is, according to our belief, coupled with \gls{reid}. As recent work of~\cite{kuma2019vehiclereid} suggests, for instance, identification of faces has been researched a lot deeper than vehicles. The two tasks are similar, yet the common conviction is that despite the intra-class variations, the identity of a vehicle is less fine-grained compared to other objects, e.g. people~\cite{kuma2019vehiclereid}. Multiple papers, such as~\cite{schroff2015facenet, hermans2017triplet}, show promising results in the training of machine learning models when using embeddings, specifically when applying the triplet loss function referred to earlier.

As the key element of our approach will undoubtedly be deep learning, an adequate dataset will be imperative, whether newly created or re-used, and modified accordingly. Because of this, we could contribute to the current base of datasets available online with our work, too.
