\chapter{Introduction}
\label{chap:Introduction}

\Gls{vot} is one of the principal challenges in the field of computer vision is to locate a certain object in all frames of a video, given only its position in the first frame. An object is firstly detected in the image (frame) and a unique identifier is assigned to it. Subsequently, the same identifier has to be correctly assigned if the object is present in future images. Tracking can also be considered a task of estimating an objectâ€™s trajectory throughout a sequence of images.

Object tracking is the task of following one or more objects in a scene, from their first appearance to their exit~\cite{forsyth2012computer}. In general, this problem is still wide-open, with \gls{sota} performances lagging far behind human levels. However, there are successful real-world applications, particularly when a certain amount of control over the environment is possible, \egtext{} in industrial settings. Major difficulties stem from a change in object illumination, position, and orientation due to movement, object and camera viewpoint variations, and partial or full occlusion \cite{jalal2012sotavot}.

The goal of an object tracker is to produce a trajectory of a given object with respect to time using its position in every video frame. A practically unattainable (ideal) tracking algorithm should have the properties below~\cite{jalal2012sotavot}:
\begin{itemize}
    \item properly detect all the objects that enter and exit the scene,
    \item differentiate between instances of multiple objects,
    \item consistently maintain the uniquely assigned identifier to each object,
    \item motion of the object or lack thereof should not influence the object tracking,
    \item partial or full object occlusion, even a long-term one, should be resolved.
\end{itemize}

From a methodological perspective, \gls{vot} may be tackled in two fundamentally distinct ways, namely \emph{top-down} and \emph{bottom-up}~\cite{jalal2012sotavot}. Using the top-down methodology, an attempt is made at every frame to locate the object given some initial hypothesis~\cite{comaniciu2003kernel}. On the other hand, the bottom-up approach utilizes the object detection first and then the adequate correspondence is established with previously detected objects~\cite{wren1997pfinder}.

The field of computer vision has provided diverse approaches to visual tracking in the past decades, \egtext{}, using geometry and manual feature-engineering in combination with Kalman filtering~\cite{kalman1960linearfilter} for predicting future states. The Hungarian algorithm~\cite{kuhn1995hungarian} is the most commonly used to solve the minimum cost assignment problem, as utilized by~\cite{bawley2016simple}.

However, the most influential approaches were the ones involving the modern tools of machine learning, especially deep machine learning. Deep learning can perform global generalization, making it a valuable tool as a function approximator. This revolutionary idea which has in the past decade reaped an upsurge in its utility will be the key element of this thesis. Krizhevsky~\etal{}~\cite{krizhevsky2012classification} showed that an outstanding tool, when it comes to the application of deep learning in computer vision, are \glspl{cnn} (\sectiontext{}~\ref{ssec:ConvolutionalNeuralNetworks}). It is a predominant approach to extract valuable visual features from the pixel space of images as well as a fundamental building block of our work.

Visual tracking of single or multiple objects is often just an intermediate step for various ends. In this work, the traffic analysis, specifically, tracking vehicles, is considered to be the primary target of our applied research, even though, as we will see later, our developed methods are generally applicable regardless of this specific use case. Besides traffic analysis~\cite{tang2019cityflow}, whether from a static camera or as part of self-driving cars, there are pedestrian detection and tracking~\cite{lealtaixe2017tracking}, activity understanding~\cite{finn2017oneshotimitation}, and imitation based on a video~\cite{peng2018sfv}. While this is an important problem, the current \gls{sota} solutions still lack high accuracy in unconstrained scenarios with potential object occlusion~\cite{jiyan2007robustocclusion}. Understandably, the object might re-emerge after the occlusion in a significantly different form, thus it might be mistaken for a new object. Occlusion comes in three separate types~\cite{gabriel2003sotamot}:
\begin{itemize}
    \item \emph{self-occlusion}, where the object occludes itself (a person holding a phone),
    \item \emph{intra-object occlusion}, in which multiple different objects occlude each other (a small vehicle passing behind a truck),
    \item or \emph{object-background occlusion}, when the occlusion is caused by a static object in the background (a tree occluding a cat).
\end{itemize}

A key element for a tracking algorithm to hold onto when dealing with occlusion is to discern between new and previously seen objects. For this purpose, a repeated identification of some object, or \gls{reid}, is indispensable. Various advances in the creation of latent spaces and \emph{embeddings} using deep learning (\sectiontext{}~\ref{ssec:ArtificialNeuralNetworks}) have shown promising results~\cite{schroff2015facenet, taigman2014deepface}. One use case of embeddings is to create a metric space into which the tracked visual objects are encoded as vectors. It is a form of dimensionality reduction, where similar objects are mapped onto a manifold closer together while distinct objects are mapped further away from each other~\cite{hadsell2006dimreduction}.

A broad range of real-life applications requires tracking multiple objects, which only adds complexity to an already tough problem itself. But~\cite{kuma2019vehiclereid} shows that approaching the problem of vehicle \gls{reid} using embeddings (\sectiontext{}~\ref{sec:LatentSpacesAndEmbeddings}) trained with contrastive or triplet loss (\sectiontext{}~\ref{ssec:SiameseAndTripletNetworks}) brings substantial improvement. We plan to explore this idea and utilize it as a basis for \gls{vot} when it comes to repeatedly re-identify occluded objects.

The primary objective of this thesis is to explore, implement, and experiment with methods for \gls{vot} using tools of deep learning. Given the potential for improvement, considering the performance of \gls{sota} approaches as well as the practical demand for an accurate tracking outcome, be it traffic or other scenarios~\cite{tang2019cityflow}, we think that an emphasis should be put on occlusion handling, whether partial or full, as it causes major difficulties for existing methods~\cite{jiyan2007robustocclusion}.

The secondary objective is to extend the current knowledge in the field of computer vision and deep learning regarding dynamic scenes involving \gls{vot}. Nowadays, at the time of writing this document, there is still a lack of freely available implementations. Widely used open-source libraries such as \opencv{}~\cite{bradski2000opencv} provide only tracking algorithms for single objects, as opposed to \gls{mot}, which is demanded in practice, yet concrete solutions exist but are not ubiquitous and easy to use.

The rest of the document is organized as follows. The main goals of this dissertation thesis are described in \chaptertext{}~\ref{chap:Goals}, discussed next. To equip the reader with the necessary foundational knowledge we provide \chaptertext{}~\ref{chap:TheoreticalFoundations}. Right after this chapter, we composed a short treatise on available and used datasets in \chaptertext{}~\ref{chap:RelevantDatasetsOverview}. At this point, we start with our first relevant experiment related to homography transformations, to which an entire \chaptertext{}~\ref{chap:HomographyRanking} is dedicated. This chapter is a one-to-one re-write and expansion of our published paper, so this work can be treated as finished and successfully published. Then, we have \chaptertext{}~\ref{chap:DevelopedSiameseTrackingApproaches}, focused on our developed approaches to \gls{vot}. It is by far the most important chapter and presents the greatest part of our work. Our achieved results are discussed subsequently in \chaptertext{}~\ref{chap:DiscussionConclusion}, which closes the entire document with a conclusion.