\chapter{Introduction}
\label{chap:Introduction}

% ==============================================================================
% .......... definition
\Gls{vot} is one of the principal challenges in the field of computer vision and has consistently been a popular research area over the last two decades. The popularity has been propelled by significant research challenges tracking offers as well as the industrial potential of tracking-based applications. Briefly speaking, the task is to locate a certain object in all frames of a video, given only its location in the first frame. From a technical perspective, an object is firstly detected in the image (frame), a unique identifier is assigned to it and subsequently, the same identifier has to be correctly assigned, if the object is present in future images from the scene. On a local level \gls{vot} typically involves finding correspondence between key points in the static image and image in which the object has moved. It is important to remark that such correspondence may be ambiguous or temporarily non-existent. Tracking can also be considered a task of estimating an object’s trajectory throughout a sequence of images, such as video frames.

% .......... major difficulties
\Gls{vot} is a task at which people perform reasonably well, but when it comes to computers, it is considered practically unsolved, especially when trying to track multiple objects, further referred to as \gls{mot}. With this in mind, object tracking is the task of following one or more objects in a scene, from their first appearance to their exit~\cite{forsyth2012computer}. In general, \gls{mot} is still wide-open, with \gls{sota} performances lagging far behind human levels. However, there are successful real-world applications, particularly when a certain amount of control over the environment is possible, e.g. in industrial settings. Major difficulties stem from a change in object illumination, position, and orientation due to movement, object and camera viewpoint variations, and partial or full occlusion after which the object re-emerges in the scene again~\cite{jalal2012sotavot}.

% .......... official challenges
As a still largely unsolved and active area of research, there is an extensive literature covering different approaches. Since $2013$, there has even been a standard benchmark in the field, called the \gls{vot} Challenge~\cite{webvotchallenge}, which maintains datasets that researchers and individuals can use to benchmark their algorithms. Another competitive type of a benchmark exist under the name \gls{otb}~\cite{wu2015otb}. Additionally, a similar type of evaluation and comparison of numerous approaches for the \gls{mot} exists since 2014 under the name \gls{mot} Challenge~\cite{webmotchallenge}, too. The most recent, completed, and relevant results of these challenges for our work are~\cite{kristan2018vot18, kristan2019motyolovot19, dendorfer2019cvpr}. Such an extensive endeavor to push the boundaries of object tracking performance supports the relevancy of this topic.

% .......... goal
The goal of an object tracker is to produce a trajectory of a given object with respect to time using its position in every video frame. A practically unattainable, an ideal tracking algorithm, should as a result have the properties below~\cite{jalal2012sotavot}:

\begin{itemize}
    \item properly detect all the objects that enter and exit the scene,
    \item differentiate between instances of multiple objects present at simultaneously,
    \item consistently maintain the uniquely assigned label (identifier) to each object,
    \item motion of the object or lack thereof should not influence the object tracking,
    \item partial or full object occlusion, even a long-term one, should be resolved.
\end{itemize}

% .......... methodological perspective (top-down vs bottom-up)
From a methodological perspective, \gls{vot} may be tackled in two fundamentally distinct ways, namely \emph{top-down} and \emph{bottom-up}~\cite{jalal2012sotavot}. The top-down methodology employs \emph{forward tracking}, which means that an attempt is made at every frame to locate the object given some initial hypothesis. This hypothesis depends upon the chosen feature representation of the object. An example may be a simple template matching~\cite{comaniciu2003kernel}. On the other hand, the bottom-up approach utilizes the object detection first and then the adequate correspondence is established with previously detected objects. A BLOB-based tracking~\cite{wren1997pfinder} is one example of this approach, and it is safe to declare that our intention is identical. We plan to analyze and exploit the capabilities of the \gls{sota} object detectors to localize objects of interest (primarily vehicles in our use case) and then build the object tracking pipeline.

% .......... old approaches
The field of computer vision has provided diverse approaches to visual tracking in the past decades, e.g. using geometry and manual feature-engineering in combination with Kalman filtering~\cite{kalman1960linearfilter} (section \ref{ssec:KalmanFiler}) for predicting future states. The Hungarian algorithm~\cite{kuhn1995hungarian} is the most commonly used to solve the assignment problem in a bipartite graph, as utilized by~\cite{bawley2016simple}. The assignment problem emerges when the decision whether the newly detected object should be assigned to an already existing track or a new one has to be instantiated. However, the most influential approaches were the ones involving the modern tools of machine learning, specifically deep machine learning. Deep learning can perform global generalization, which makes it a valuable tool as a function approximator, so the utilization is vast. This revolutionary idea which has in the past decade reaped an upsurge in its utility will be the key element of this thesis and we will devote the largest portion of our work to it.

% .......... modern approaches
\cite{krizhevsky2012classification} showed that an outstanding tool, when it comes to the application of deep learning in computer vision, are \glspl{cnn} (section \ref{ssec:ConvolutionalNeuralNetworks}), a predominant approach to extract valuable visual features from pixel space of images. In the context of object tracking, contemporary research shows a reasonable utility of \glspl{rnn}~\cite{rumelhart1986backprop} for prediction, and sporadically reinforcement learning for proper assignment of object identifiers~\cite{zhang2017deeprlintracking}.~\cite{hochreiter1997lstm} introduced a specific type of \gls{rnn}, the \gls{lstm}, which is one of the best approaches for modeling of time-dependent systems.

% .......... use cases transition to occlusion
Visual tracking of single or multiple objects is often just an intermediate step for various ends, such as traffic analysis~\cite{tang2019cityflow}, whether from a static camera or as part of self-driving cars, pedestrian detection and tracking~\cite{lealtaixe2017tracking}, activity understanding~\cite{finn2017oneshotimitation}, and imitation based on a video~\cite{peng2018sfv}. While this is an important problem with annually occurring challenges for the best achievement, the current \gls{sota} solutions still lack high accuracy in unconstrained scenarios with potential object occlusion~\cite{jiyan2007robustocclusion}. Understandably, the object might re-emerge after the occlusion in a significantly different form, thus it might be mistaken for a new object. Occlusion comes in three separate types~\cite{gabriel2003sotamot}:
\begin{itemize}
    \item \emph{self-occlusion}, where the object occludes itself (a person holding a phone),
    \item \emph{intra-object occlusion}, in which multiple different objects occlude each other (a small vehicle passing behind a truck),
    \item or \emph{object-background occlusion}, when the occlusion is caused by a static object in the background (a tree occluding a cat).
\end{itemize}
In traffic scenarios, the last two types are prevalent.

% .......... embeddings and latent spaces
A key element for a tracking algorithm to hold onto when dealing with occlusion is to discern between new and previously seen objects. For this purpose, a repeated identification of some object, or \gls{reid}, is indispensable, notably when visual clues are decisive. Various advances in the creation of latent spaces and so-called \emph{embeddings} using deep neural networks (section \ref{ssec:ArtificialNeuralNetworks}) have shown promising results concerning object \gls{reid}, especially for people~\cite{schroff2015facenet, taigman2014deepface}. One use case of embeddings is to create a metric space into which the tracked visual objects are encoded as vectors. It is a form of dimensionality reduction, where similar objects are mapped onto a manifold closer together while distinct objects are mapped further away from each other~\cite{hadsell2006dimreduction}. Later on, the Euclidean distance or cosine similarity between any two vectors results in a high degree of similarity if the two visual samples belong to the same object. This metric can be tailor-made to a custom form of similarity. In our case, all such comparisons should handle various visual changes in the object character, as~\cite{kuma2019vehiclereid} comprehensively demonstrated on vehicles.

A broad range of real-life applications require tracking of multiple objects, which only adds complexity to an already tough problem itself. But~\cite{kuma2019vehiclereid} shows that approaching the problem of vehicle \gls{reid} using embeddings (section \ref{sec:LatentSpacesAndEmbeddings}) trained with contrastive or triplet loss (section \ref{ssec:SiameseAndTripletNetworks}) brings substantial improvement. We plan to explore this idea and utilize it as a basis for \gls{vot} when it comes to repeatedly re-identify occluded objects.

% .......... motion prediction
As far as occlusion is concerned, a robust prediction of the object movement would contribute to the model performance. Considering present-day publications~\cite{tan2019motyolo}, linear models seem to have become obsolete and were replaced by \glspl{rnn} to learn the intricate nonlinear, hidden state of the object, for an improved prediction of the object’s trajectory. Vehicles are not subject to extreme changes in their position between individual video frames and that opens up an opportunity of reliance on physical laws in case of long-term object occlusion, so this possibility will be examined further (section \ref{sec:PredictingMotion}).

% .......... primary objective of the thesis
The primary objective of this thesis is to explore, implement, and experiment with methods for \gls{vot} using tools of deep learning, primarily \glspl{cnn}, with a prospect to employ capabilities of \glspl{rnn} and reinforcement learning, if necessary. Given the potential for improvement, considering the performance of \gls{sota} approaches as well as the practical demand for an accurate tracking outcome, be it traffic or other scenarios~\cite{tang2019cityflow}, we think that an emphasis should be put on occlusion handling, as it causes major difficulties for existing methods~\cite{jiyan2007robustocclusion}.

% .......... secondary objective of the thesis
The secondary objective is to extend the current knowledge in the field of computer vision and deep machine learning with respect to dynamic scenes involving \gls{vot}. Nowadays, at the time of writing this document, there is still a lack of freely available implementations. Widely used open-source libraries such as OpenCV~\cite{bradski2000opencv} provide only tracking algorithms for single objects, as opposed to \gls{mot}, which is demanded in practice, yet concrete solutions exist but are not ubiquitous and easy to use. Visual tracking in the presence of occlusion is, according to our belief, coupled with \gls{reid}. As recent work of~\cite{kuma2019vehiclereid} suggest, for instance, identification of faces has been researched a lot deeper than vehicles. The two tasks are similar, yet the common conviction is that despite the intra-class variations, the identity of a vehicle is less fine-grained compared to other objects, e.g. people~\cite{kuma2019vehiclereid}. Multiple papers, such as~\cite{schroff2015facenet, hermans2017triplet}, show promising results in training of machine learning models when using embeddings, specifically when applying the triplet loss function referred to earlier.

As the key element of our approach will undoubtedly be deep learning, an adequate dataset will be imperative, whether newly created or re-used and modified accordingly. Because of this, we could contribute to the current base of datasets available online with our work, too. There are not many usable datasets for vehicle \gls{reid}, as opposed to already mentioned person \gls{reid}.~\cite{liu2018provid, yan2017exploiting} created currently one of the best datasets available where the vehicle is caught from various angles in an uncontrolled environment (section \ref{sec:ObjectReIDDatasets}). Besides various changes in the angle of view and high-quality data annotations, other auxiliary information such as car manufacturers and colors are provided, too. Unfortunately, these datasets are available only upon request, but still for free. A discussion regarding datasets can be found in chapter \ref{chap:SurveyOfDatasets}. This supports the claim that vehicle \gls{reid} lacks freely available data in general and authors scrupulously protect their contribution to this newly emerging sub-field. In the end, our goal is to build upon their work and contribute to the palette of approaches when dealing with tracking vehicles visually, especially when occlusion poses a real threat in dynamic scenes of traffic.
